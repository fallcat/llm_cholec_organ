Evaluating gpt-4.1 Pointing
==========================================
Evaluation Configuration
==========================================
Number of samples: 100
Models: gpt-4.1
Cell selection: SKIPPED
Pointing: ENABLED
Persistent directories: true
API caching: false

==========================================
Pointing Evaluation
==========================================
Output: ../results/pointing_original/

âœ“ Environment setup complete

============================================================
Pointing Evaluation Configuration (Original Image Size)
============================================================
Samples: 100
Models: gpt-4.1
Cache: disabled
Enhanced metrics: enabled
Skip zero-shot: False
Skip few-shot: False

To customize, either:
1. In notebooks: Call main() directly with parameters
2. Set environment variables before running:
   export EVAL_NUM_SAMPLES=10
   export EVAL_MODELS='gpt-5-mini,claude-sonnet-4-20250514'
   export EVAL_USE_CACHE=false  # to disable cache
   export EVAL_USE_ENHANCED=false  # to disable enhanced metrics
   export EVAL_SKIP_ZERO_SHOT=true  # to skip zero-shot
   export EVAL_SKIP_FEW_SHOT=true  # to skip few-shot
   export EVAL_QUICK_TEST=true
3. Or run inline: EVAL_SKIP_ZERO_SHOT=true python3 eval_pointing_original_size.py
============================================================


============================================================
Starting Pointing Evaluation (Original Image Size)
============================================================
Models to evaluate: gpt-4.1

ðŸ“Š Loading CholecSeg8k dataset...
âœ“ Dataset loaded
âœ“ Using original image dimensions: 854x480
âœ“ Loaded 100 test samples
âœ“ Loaded few-shot plan: standard
âœ“ Loaded few-shot plan: hard_negatives
âœ“ Using persistent directory: ../results/pointing_original
Initialized evaluator:
  Models: ['gpt-4.1']
  Organs: 12
  Canvas: 854x480
  Output: ../results/pointing_original

ðŸ“Š Evaluating 100 test samples with enhanced metrics

============================================================
Evaluating: gpt-4.1
============================================================

ðŸ”„ Running zero-shot with gpt-4.1 (enhanced metrics)...
gpt-4.1 zero-shot:   0%|          | 0/100 [00:00<?, ?it/s]gpt-4.1 zero-shot:   3%|â–Ž         | 3/100 [00:24<12:59,  8.04s/it]gpt-4.1 zero-shot:   4%|â–         | 4/100 [00:50<22:17, 13.94s/it]gpt-4.1 zero-shot:   5%|â–Œ         | 5/100 [01:14<27:09, 17.15s/it]gpt-4.1 zero-shot:   6%|â–Œ         | 6/100 [01:37<29:53, 19.08s/it]gpt-4.1 zero-shot:   7%|â–‹         | 7/100 [02:05<33:31, 21.63s/it]gpt-4.1 zero-shot:   8%|â–Š         | 8/100 [02:31<35:15, 22.99s/it]gpt-4.1 zero-shot:   9%|â–‰         | 9/100 [02:59<37:14, 24.56s/it]gpt-4.1 zero-shot:  10%|â–ˆ         | 10/100 [03:28<38:59, 25.99s/it]gpt-4.1 zero-shot:  11%|â–ˆ         | 11/100 [03:53<37:59, 25.61s/it]gpt-4.1 zero-shot:  12%|â–ˆâ–        | 12/100 [04:19<37:41, 25.69s/it]gpt-4.1 zero-shot:  13%|â–ˆâ–Ž        | 13/100 [04:46<37:56, 26.17s/it]gpt-4.1 zero-shot:  14%|â–ˆâ–        | 14/100 [05:11<37:00, 25.82s/it]gpt-4.1 zero-shot:  15%|â–ˆâ–Œ        | 15/100 [05:38<37:08, 26.22s/it]gpt-4.1 zero-shot:  16%|â–ˆâ–Œ        | 16/100 [06:05<36:48, 26.30s/it]gpt-4.1 zero-shot:  17%|â–ˆâ–‹        | 17/100 [06:30<35:45, 25.85s/it]gpt-4.1 zero-shot:  18%|â–ˆâ–Š        | 18/100 [06:54<34:47, 25.46s/it] zero-shot:  17%|â–ˆâ–‹        | 17/100 [07:32<35:13, 25.46s/it]gpt-4.1 zero-shot:  18%|â–ˆâ–Š        | 18/100 [07:59<35:17, 25.82s/it]gpt-4.1 zero-shot:  19%|â–ˆâ–‰        | 19/100 [08:24<34:21, 25.45s/it]